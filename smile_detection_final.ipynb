{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3VfDA4uVnPz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAzMod8tWWP4",
        "outputId": "c012b0a9-ed01-4848-e939-5e0cb8d4832f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python-headless) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless  # Headless for Colab (no GUI)\n",
        "import os\n",
        "import zipfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41iKAPGfhWQs",
        "outputId": "1cf0b943-d0fc-4626-ec53-1206e2c09717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "UTKFace images: 23708\n",
            "CelebA images: 10002\n",
            "Annotations exist: True\n",
            "Sample CelebA files: ['009080.jpg', '009008.jpg', '009086.jpg', '009065.jpg', '009018.jpg']\n",
            "\n",
            "Checking UTKFace resolutions...\n",
            "UTKFace sample size: 100\n",
            "Unique resolutions: {(200, 200)}\n",
            "Resolution counts: {(200, 200): 100}\n",
            "\n",
            "Checking CelebA resolutions...\n",
            "CelebA sample size: 100\n",
            "Unique resolutions: {(178, 218)}\n",
            "Resolution counts: {(178, 218): 100}\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "drive            15G  9.2G  5.9G  61% /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Remount for fresh access\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "utkface_img_dir = os.path.join(base_dir, 'UTKFace/UTKFace')\n",
        "celeba_img_dir = os.path.join(base_dir, 'celeba/img_align_celeba')\n",
        "celeba_anno_path = os.path.join(base_dir, 'celeba/Anno/list_attr_celeba.txt')\n",
        "\n",
        "# Verify files\n",
        "print(f\"UTKFace images: {len([f for f in os.listdir(utkface_img_dir) if f.endswith('.jpg')]) if os.path.exists(utkface_img_dir) else 'Path issue'}\")\n",
        "print(f\"CelebA images: {len([f for f in os.listdir(celeba_img_dir) if f.endswith('.jpg')]) if os.path.exists(celeba_img_dir) else 'Path issue'}\")\n",
        "print(f\"Annotations exist: {os.path.exists(celeba_anno_path)}\")\n",
        "print(\"Sample CelebA files:\", os.listdir(celeba_img_dir)[:5] if os.path.exists(celeba_img_dir) else \"No files\")\n",
        "\n",
        "# Check resolutions (sample 100 images each)\n",
        "def get_image_resolution(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    return (img.shape[1], img.shape[0])  # Width, Height\n",
        "\n",
        "print(\"\\nChecking UTKFace resolutions...\")\n",
        "utkface_resolutions = []\n",
        "if os.path.exists(utkface_img_dir):\n",
        "    utkface_files = [f for f in os.listdir(utkface_img_dir) if f.endswith('.jpg')][:100]\n",
        "    for f in utkface_files:\n",
        "        res = get_image_resolution(os.path.join(utkface_img_dir, f))\n",
        "        if res:\n",
        "            utkface_resolutions.append(res)\n",
        "    unique_utkface_res = set(utkface_resolutions)\n",
        "    print(f\"UTKFace sample size: {len(utkface_resolutions)}\")\n",
        "    print(f\"Unique resolutions: {unique_utkface_res}\")\n",
        "    print(f\"Resolution counts: {pd.Series(utkface_resolutions).value_counts().to_dict()}\")\n",
        "\n",
        "print(\"\\nChecking CelebA resolutions...\")\n",
        "celeba_resolutions = []\n",
        "if os.path.exists(celeba_img_dir):\n",
        "    celeba_files = [f for f in os.listdir(celeba_img_dir) if f.endswith('.jpg')][:100]\n",
        "    for f in celeba_files:\n",
        "        res = get_image_resolution(os.path.join(celeba_img_dir, f))\n",
        "        if res:\n",
        "            celeba_resolutions.append(res)\n",
        "    unique_celeba_res = set(celeba_resolutions)\n",
        "    print(f\"CelebA sample size: {len(celeba_resolutions)}\")\n",
        "    print(f\"Unique resolutions: {unique_celeba_res}\")\n",
        "    print(f\"Resolution counts: {pd.Series(celeba_resolutions).value_counts().to_dict()}\")\n",
        "\n",
        "# Check Drive usage\n",
        "!df -h /content/drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf62D0cfI7qY",
        "outputId": "b0233e70-6617-405b-8be2-20c47119d54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UTKFace loaded: 23705 images, age range: 1 to 116\n",
            "CelebA loaded: 10002 images, smile distribution: {0: 5179, 1: 4823}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "utkface_img_dir = os.path.join(base_dir, 'UTKFace/UTKFace')\n",
        "celeba_img_dir = os.path.join(base_dir, 'celeba/img_align_celeba')\n",
        "celeba_anno_path = os.path.join(base_dir, 'celeba/Anno/list_attr_celeba.txt')\n",
        "\n",
        "# UTKFace\n",
        "utkface_data = []\n",
        "for filename in os.listdir(utkface_img_dir):\n",
        "    if filename.endswith('.jpg'):\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) >= 4:\n",
        "            try:\n",
        "                age = int(parts[0])\n",
        "                img_path = os.path.join(utkface_img_dir, filename)\n",
        "                utkface_data.append({'path': img_path, 'age': age})\n",
        "            except ValueError:\n",
        "                pass\n",
        "utkface_df = pd.DataFrame(utkface_data)\n",
        "print(f\"UTKFace loaded: {len(utkface_df)} images, age range: {utkface_df['age'].min()} to {utkface_df['age'].max()}\")\n",
        "\n",
        "# CelebA\n",
        "try:\n",
        "    celeba_df = pd.read_csv(celeba_anno_path)  # Handles CSV format\n",
        "    celeba_df['smile'] = celeba_df['Smiling'].replace({-1: 0, 1: 1})\n",
        "    celeba_df['filename'] = celeba_df.iloc[:, 0]  # First column is image filename\n",
        "    celeba_df['path'] = [os.path.join(celeba_img_dir, fn) for fn in celeba_df['filename']]\n",
        "    extracted_files = set(os.listdir(celeba_img_dir))\n",
        "    celeba_sample = celeba_df[celeba_df['filename'].isin(extracted_files)].copy()\n",
        "    print(f\"CelebA loaded: {len(celeba_sample)} images, smile distribution: {celeba_sample['smile'].value_counts().to_dict()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Annotation file not found at {celeba_anno_path}\")\n",
        "    raise\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Error parsing CelebA annotations. Checking file:\")\n",
        "    !head -n 5 \"{celeba_anno_path}\"\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBWA2qPWpJJn",
        "outputId": "7b064af3-7d00-43d6-bdde-2863c6702320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cleaning UTKFace...\n",
            "UTKFace cleaned: 4209 images\n",
            "Cleaning CelebA...\n",
            "CelebA cleaned: 9254 images\n",
            "Cleaning complete. Saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from multiprocessing import Pool # Import Pool for multiprocessing\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "utkface_img_dir = os.path.join(base_dir, 'UTKFace/UTKFace')\n",
        "celeba_img_dir = os.path.join(base_dir, 'celeba/img_align_celeba')\n",
        "\n",
        "# Load face cascade (uses GPU-accelerated DNN if available)\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def is_valid_image(img_path, blur_threshold=50):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return False\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
        "    if len(faces) != 1:\n",
        "        return False\n",
        "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    return laplacian_var >= blur_threshold\n",
        "\n",
        "# Get all image paths\n",
        "utkface_paths = [os.path.join(utkface_img_dir, f) for f in os.listdir(utkface_img_dir) if f.endswith('.jpg')]\n",
        "celeba_paths = [os.path.join(celeba_img_dir, f) for f in os.listdir(celeba_img_dir) if f.endswith('.jpg')]\n",
        "\n",
        "# Clean UTKFace using multiprocessing\n",
        "print(\"Cleaning UTKFace...\")\n",
        "utkface_clean_data = []\n",
        "with Pool(processes=4) as pool: # Use a pool of processes\n",
        "    valid_utkface_paths = pool.map(is_valid_image, utkface_paths)\n",
        "\n",
        "for i, is_valid in enumerate(valid_utkface_paths):\n",
        "    if is_valid:\n",
        "        path = utkface_paths[i]\n",
        "        filename = os.path.basename(path)\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) >= 4:\n",
        "            try:\n",
        "                age = int(parts[0])\n",
        "                utkface_clean_data.append({'path': path, 'age': age})\n",
        "            except ValueError:\n",
        "                continue\n",
        "utkface_clean_df = pd.DataFrame(utkface_clean_data)\n",
        "print(f\"UTKFace cleaned: {len(utkface_clean_df)} images\")\n",
        "\n",
        "# Clean CelebA using multiprocessing (load labels first for smile)\n",
        "print(\"Cleaning CelebA...\")\n",
        "celeba_anno_path = os.path.join(base_dir, 'celeba/Anno/list_attr_celeba.txt')\n",
        "celeba_df_labels = pd.read_csv(celeba_anno_path) # Load labels separately\n",
        "celeba_df_labels['smile'] = celeba_df_labels['Smiling'].replace({-1: 0, 1: 1})\n",
        "celeba_df_labels['filename'] = celeba_df_labels.iloc[:, 0]\n",
        "\n",
        "celeba_clean_data = []\n",
        "with Pool(processes=4) as pool: # Use a pool of processes\n",
        "    valid_celeba_paths = pool.map(is_valid_image, celeba_paths)\n",
        "\n",
        "for i, is_valid in enumerate(valid_celeba_paths):\n",
        "    if is_valid:\n",
        "        path = celeba_paths[i]\n",
        "        filename = os.path.basename(path)\n",
        "        if filename in celeba_df_labels['filename'].values:\n",
        "            smile = celeba_df_labels.loc[celeba_df_labels['filename'] == filename, 'smile'].iloc[0]\n",
        "            celeba_clean_data.append({'path': path, 'smile': smile})\n",
        "celeba_clean_df = pd.DataFrame(celeba_clean_data)\n",
        "print(f\"CelebA cleaned: {len(celeba_clean_df)} images\")\n",
        "\n",
        "\n",
        "# Save cleaned DataFrames\n",
        "utkface_clean_df.to_csv(os.path.join(base_dir, 'utkface_clean.csv'), index=False)\n",
        "celeba_clean_df.to_csv(os.path.join(base_dir, 'celeba_clean.csv'), index=False)\n",
        "print(\"Cleaning complete. Saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split  # Added missing import\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "utkface_clean_path = os.path.join(base_dir, 'utkface_clean.csv')\n",
        "celeba_clean_path = os.path.join(base_dir, 'celeba_clean.csv')\n",
        "\n",
        "# Load cleaned DataFrames\n",
        "utkface_clean_df = pd.read_csv(utkface_clean_path)\n",
        "celeba_clean_df = pd.read_csv(celeba_clean_path)\n",
        "\n",
        "print(f\"UTKFace loaded: {len(utkface_clean_df)} images\")\n",
        "print(f\"CelebA loaded: {len(celeba_clean_df)} images\")\n",
        "\n",
        "# Balance CelebA to match UTKFace size (stratified by smile)\n",
        "target_size = len(utkface_clean_df)  # 4209\n",
        "if len(celeba_clean_df) > target_size:\n",
        "    _, celeba_balanced_df = train_test_split(celeba_clean_df, train_size=target_size, stratify=celeba_clean_df['smile'], random_state=42)\n",
        "    celeba_clean_df = celeba_balanced_df\n",
        "    print(f\"CelebA balanced to match UTKFace: {len(celeba_clean_df)} images\")\n",
        "\n",
        "# Save balanced cleaned DataFrames\n",
        "utkface_clean_df.to_csv(os.path.join(base_dir, 'utkface_clean.csv'), index=False)\n",
        "celeba_clean_df.to_csv(os.path.join(base_dir, 'celeba_clean.csv'), index=False)\n",
        "print(\"Balancing complete. Saved to CSV files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvQUVqQAAkE4",
        "outputId": "a6e8f476-ee9d-4217-f6df-3beba057ddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "UTKFace loaded: 4209 images\n",
            "CelebA loaded: 9254 images\n",
            "CelebA balanced to match UTKFace: 5045 images\n",
            "Balancing complete. Saved to CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from multiprocessing import Pool\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "utkface_clean_path = os.path.join(base_dir, 'utkface_clean.csv')\n",
        "celeba_clean_path = os.path.join(base_dir, 'celeba_clean.csv')\n",
        "utkface_output_dir = os.path.join(base_dir, 'processed_utkface')\n",
        "celeba_output_dir = os.path.join(base_dir, 'processed_celeba')\n",
        "os.makedirs(utkface_output_dir, exist_ok=True)\n",
        "os.makedirs(celeba_output_dir, exist_ok=True)\n",
        "\n",
        "# Load cleaned DataFrames\n",
        "utkface_df = pd.read_csv(utkface_clean_path)\n",
        "celeba_df = pd.read_csv(celeba_clean_path)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.1, 5)\n",
        "    if len(faces) == 1:\n",
        "        x, y, w, h = faces[0]\n",
        "        face = img[max(0, y-20):y+h+20, max(0, x-20):x+w+20]\n",
        "        resized = cv2.resize(face, (128, 128))\n",
        "        normalized = resized / 255.0\n",
        "        filename = os.path.basename(img_path).replace('.jpg', '.npy')\n",
        "        save_path = os.path.join(utkface_output_dir if 'UTKFace' in img_path else celeba_output_dir, filename)\n",
        "        np.save(save_path, normalized)\n",
        "        return save_path\n",
        "    return None\n",
        "\n",
        "# Parallel processing\n",
        "with Pool(processes=4) as pool:\n",
        "    utkface_results = pool.map(preprocess_image, utkface_df['path'].tolist())\n",
        "    celeba_results = pool.map(preprocess_image, celeba_df['path'].tolist())\n",
        "\n",
        "# Update DataFrames with processed paths and align with valid results\n",
        "utkface_df = utkface_df.copy()  # Avoid SettingWithCopyWarning\n",
        "celeba_df = celeba_df.copy()\n",
        "utkface_df['processed_path'] = utkface_results  # Assign all results, including None\n",
        "celeba_df['processed_path'] = celeba_results\n",
        "utkface_df = utkface_df.dropna(subset=['processed_path'])  # Drop rows where processing failed\n",
        "celeba_df = celeba_df.dropna(subset=['processed_path'])\n",
        "\n",
        "# Save updated DataFrames\n",
        "utkface_df.to_csv(os.path.join(base_dir, 'utkface_processed.csv'), index=False)\n",
        "celeba_df.to_csv(os.path.join(base_dir, 'celeba_processed.csv'), index=False)\n",
        "print(f\"Preprocessed: UTKFace {len(utkface_df)} images, CelebA {len(celeba_df)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtiNHoHtAtVS",
        "outputId": "6386cf4d-9fdb-47bb-8515-e8cf85bf07b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Preprocessed: UTKFace 4208 images, CelebA 5041 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "utkface_processed_path = os.path.join(base_dir, 'utkface_processed.csv')\n",
        "celeba_processed_path = os.path.join(base_dir, 'celeba_processed.csv')\n",
        "\n",
        "# Load preprocessed DataFrames\n",
        "utkface_df = pd.read_csv(utkface_processed_path)\n",
        "celeba_df = pd.read_csv(celeba_processed_path)\n",
        "\n",
        "print(f\"UTKFace loaded: {len(utkface_df)} images\")\n",
        "print(f\"CelebA loaded: {len(celeba_df)} images\")\n",
        "\n",
        "# Split UTKFace\n",
        "utk_train, utk_temp = train_test_split(utkface_df, test_size=0.3, random_state=42)\n",
        "utk_val, utk_test = train_test_split(utk_temp, test_size=0.5, random_state=42)\n",
        "print(f\"UTKFace split: Train {len(utk_train)}, Val {len(utk_val)}, Test {len(utk_test)}\")\n",
        "\n",
        "# Split CelebA (stratified by smile)\n",
        "celeba_train, celeba_temp = train_test_split(celeba_df, test_size=0.3, random_state=42, stratify=celeba_df['smile'])\n",
        "celeba_val, celeba_test = train_test_split(celeba_temp, test_size=0.5, random_state=42, stratify=celeba_temp['smile'])\n",
        "print(f\"CelebA split: Train {len(celeba_train)}, Val {len(celeba_val)}, Test {len(celeba_test)}\")\n",
        "\n",
        "# Save splits\n",
        "for split, name in [(utk_train, 'utk_train'), (utk_val, 'utk_val'), (utk_test, 'utk_test'),\n",
        "                    (celeba_train, 'celeba_train'), (celeba_val, 'celeba_val'), (celeba_test, 'celeba_test')]:\n",
        "    split.to_csv(os.path.join(base_dir, f'{name}.csv'), index=False)\n",
        "print(\"Splitting complete. Saved to CSV files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gvCmb9hGxHc",
        "outputId": "edf87601-1d93-4f47-a0b4-a1234cb8ecee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "UTKFace loaded: 4208 images\n",
            "CelebA loaded: 5041 images\n",
            "UTKFace split: Train 2945, Val 631, Test 632\n",
            "CelebA split: Train 3528, Val 756, Test 757\n",
            "Splitting complete. Saved to CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 \"/content/drive/MyDrive/Smilage_Project_Data/celeba/Anno/list_attr_celeba.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtnrNkAYK6NY",
        "outputId": "d1b4967d-da38-42c2-f1b2-2844604875a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_id,5_o_Clock_Shadow,Arched_Eyebrows,Attractive,Bags_Under_Eyes,Bald,Bangs,Big_Lips,Big_Nose,Black_Hair,Blond_Hair,Blurry,Brown_Hair,Bushy_Eyebrows,Chubby,Double_Chin,Eyeglasses,Goatee,Gray_Hair,Heavy_Makeup,High_Cheekbones,Male,Mouth_Slightly_Open,Mustache,Narrow_Eyes,No_Beard,Oval_Face,Pale_Skin,Pointy_Nose,Receding_Hairline,Rosy_Cheeks,Sideburns,Smiling,Straight_Hair,Wavy_Hair,Wearing_Earrings,Wearing_Hat,Wearing_Lipstick,Wearing_Necklace,Wearing_Necktie,Young\r\n",
            "000001.jpg,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,1\r\n",
            "000002.jpg,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1\r\n",
            "000003.jpg,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,1\r\n",
            "000004.jpg,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,-1,1,1,-1,1\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "celeba_anno_path = os.path.join(base_dir, 'celeba/Anno/list_attr_celeba.txt')\n",
        "celeba_processed_path = os.path.join(base_dir, 'celeba_clean.csv')\n",
        "\n",
        "# Load annotation file with proper separator\n",
        "anno_df = pd.read_csv(celeba_anno_path, sep=',')\n",
        "print(f\"Number of columns in annotation file: {len(anno_df.columns)}\")\n",
        "print(f\"Column names: {anno_df.columns.tolist()}\")\n",
        "\n",
        "# Verify and set the smile column\n",
        "if 'Smiling' not in anno_df.columns:\n",
        "    raise ValueError(\"'Smiling' column not found in the annotation file. Please check the column names.\")\n",
        "anno_df['filename'] = anno_df.iloc[:, 0]  # First column is image filename, assuming it is always the first column\n",
        "anno_df['smile'] = anno_df['Smiling'].replace({-1: 0, 1: 1})\n",
        "\n",
        "# Load preprocessed CelebA to get the subset of filenames\n",
        "processed_df = pd.read_csv(celeba_processed_path)\n",
        "processed_filenames = set(os.path.basename(p) for p in processed_df['path'])\n",
        "\n",
        "# Filter annotations to match preprocessed images\n",
        "subset_anno_df = anno_df[anno_df['filename'].isin(processed_filenames)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "# Calculate ratio\n",
        "smile_count = subset_anno_df['smile'].sum()  # Count of 1s (smiling)\n",
        "non_smile_count = len(subset_anno_df) - smile_count  # Count of 0s (non-smiling)\n",
        "total_count = len(subset_anno_df)\n",
        "\n",
        "print(f\"Total images in subset: {total_count}\")\n",
        "print(f\"Smiling images (1): {smile_count}\")\n",
        "print(f\"Non-smiling images (0): {non_smile_count}\")\n",
        "\n",
        "# Avoid division by zero if there are no non-smiling images\n",
        "if non_smile_count > 0:\n",
        "    print(f\"Ratio of smiling to non-smiling: {smile_count / non_smile_count:.2f}:1\")\n",
        "else:\n",
        "    print(\"No non-smiling images found in the subset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9_sVzsZJzD9",
        "outputId": "221c7b5d-3828-4e79-95fe-7ceb687ab9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Number of columns in annotation file: 41\n",
            "Column names: ['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
            "Total images in subset: 5045\n",
            "Smiling images (1): 2500\n",
            "Non-smiling images (0): 2545\n",
            "Ratio of smiling to non-smiling: 0.98:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Using SDG Classifier Model for smile and age prediction on the datasets\n",
        "# Import necessary libraries for smile prediction (added SGDClassifier for epochs)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.feature import hog\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier  # For epoch-based training\n",
        "from sklearn.model_selection import GridSearchCV  # For tuning to improve accuracy\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import drive, files  # Added files for upload\n",
        "import cv2  # For image processing in inference\n",
        "import joblib\n",
        "!pip install scikit-image numpy tqdm\n",
        "# Mount Google Drive to access data\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define base directory for data\n",
        "base_dir = '/content/drive/MyDrive/Smilage_Project_Data'\n",
        "\n",
        "print(\"Libraries imported and Drive mounted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In4T9gOyfXuZ",
        "outputId": "6c4f393e-5372-42d7-f41d-1896eb2d4108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.4)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Mounted at /content/drive\n",
            "Libraries imported and Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load single celeba_clean.csv and create train, val, test splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "celeba_clean_path = f'{base_dir}/celeba_clean.csv'\n",
        "\n",
        "# Read CSV into DataFrame\n",
        "celeba_df = pd.read_csv(celeba_clean_path)\n",
        "\n",
        "# Verify columns\n",
        "print(\"Columns in celeba_clean.csv:\", celeba_df.columns.tolist())\n",
        "print(\"First few rows:\")\n",
        "print(celeba_df.head())\n",
        "\n",
        "# Split into train (70%), val (15%), test (15%)\n",
        "train_df, temp_df = train_test_split(celeba_df, test_size=0.3, random_state=42, stratify=celeba_df['smile'])\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['smile'])\n",
        "\n",
        "celeba_train_df = train_df\n",
        "celeba_val_df = val_df\n",
        "celeba_test_df = test_df\n",
        "\n",
        "# Print dataset sizes and smile distribution\n",
        "print(f\"Loaded CelebA: Total {len(celeba_df)}\")\n",
        "print(f\"Train: {len(celeba_train_df)}, Val: {len(celeba_val_df)}, Test: {len(celeba_test_df)}\")\n",
        "print(f\"Smile distribution in train: {celeba_train_df['smile'].value_counts().to_dict()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvZv9tXElkMb",
        "outputId": "ffb5f3d0-0dcf-419f-d457-d9e311e125de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in celeba_clean.csv: ['path', 'smile']\n",
            "First few rows:\n",
            "                                                path  smile\n",
            "0  /content/drive/MyDrive/Smilage_Project_Data/ce...      0\n",
            "1  /content/drive/MyDrive/Smilage_Project_Data/ce...      1\n",
            "2  /content/drive/MyDrive/Smilage_Project_Data/ce...      0\n",
            "3  /content/drive/MyDrive/Smilage_Project_Data/ce...      0\n",
            "4  /content/drive/MyDrive/Smilage_Project_Data/ce...      0\n",
            "Loaded CelebA: Total 5045\n",
            "Train: 3531, Val: 757, Test: 757\n",
            "Smile distribution in train: {0: 1781, 1: 1750}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "label_file = '/content/drive/MyDrive/Smilage_Project_Data/celeba/Anno/list_attr_celeba.txt'\n",
        "with open(label_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    print(\"First 3 lines of list_attr_celeba.txt:\")\n",
        "    for i, line in enumerate(lines[:3]):\n",
        "        print(f\"Line {i+1}: {line.strip()}\")\n",
        "    if len(lines) > 1:\n",
        "        header = lines[1].strip().split()\n",
        "        print(\"\\nHeader attributes:\", header)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyjAXRmMr_ka",
        "outputId": "24dffc90-49eb-4ec2-e7c7-09e935e26d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 lines of list_attr_celeba.txt:\n",
            "Line 1: image_id,5_o_Clock_Shadow,Arched_Eyebrows,Attractive,Bags_Under_Eyes,Bald,Bangs,Big_Lips,Big_Nose,Black_Hair,Blond_Hair,Blurry,Brown_Hair,Bushy_Eyebrows,Chubby,Double_Chin,Eyeglasses,Goatee,Gray_Hair,Heavy_Makeup,High_Cheekbones,Male,Mouth_Slightly_Open,Mustache,Narrow_Eyes,No_Beard,Oval_Face,Pale_Skin,Pointy_Nose,Receding_Hairline,Rosy_Cheeks,Sideburns,Smiling,Straight_Hair,Wavy_Hair,Wearing_Earrings,Wearing_Hat,Wearing_Lipstick,Wearing_Necklace,Wearing_Necktie,Young\n",
            "Line 2: 000001.jpg,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,1\n",
            "Line 3: 000002.jpg,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1\n",
            "\n",
            "Header attributes: ['000001.jpg,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage import io, color, transform\n",
        "from skimage.feature import hog\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/drive/MyDrive/Smilage_Project_Data/celeba/img_align_celeba/'\n",
        "label_file = '/content/drive/MyDrive/Smilage_Project_Data/celeba/Anno/list_attr_celeba.txt'\n",
        "\n",
        "# Load labels\n",
        "def load_labels(label_file, attribute_name='Smiling'):\n",
        "    try:\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        # First line is the header, split on commas\n",
        "        header = lines[0].strip().split(',')  # Attribute names including 'image_id'\n",
        "        try:\n",
        "            smile_idx = header.index(attribute_name)  # Index of smile attribute\n",
        "        except ValueError:\n",
        "            print(f\"Error: '{attribute_name}' not found in header: {header}\")\n",
        "            print(\"Available attributes:\", header)\n",
        "            raise\n",
        "        labels = {}\n",
        "        for line in lines[1:]:  # Start from second line (data)\n",
        "            parts = line.strip().split(',')\n",
        "            if len(parts) > smile_idx:  # Ensure enough columns\n",
        "                img_name = parts[0]  # image_id\n",
        "                smile_label = int(parts[smile_idx])  # Smile attribute value\n",
        "                labels[img_name] = 1 if smile_label == 1 else 0  # Convert to binary (0: non-smiling, 1: smiling)\n",
        "            else:\n",
        "                print(f\"Skipping malformed line: {line.strip()}\")\n",
        "        return labels\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Label file {label_file} not found.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading label file: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Load labels\n",
        "labels = load_labels(label_file, attribute_name='Smiling')\n",
        "\n",
        "# Function to extract HOG features from an image\n",
        "def extract_hog(image_path):\n",
        "    try:\n",
        "        img = io.imread(image_path)\n",
        "        if len(img.shape) == 3:\n",
        "            img = color.rgb2gray(img)\n",
        "        img = transform.resize(img, (64, 64), anti_aliasing=True)\n",
        "        hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
        "        return hog_features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Load data and extract HOG features\n",
        "X, y = [], []\n",
        "image_files = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
        "\n",
        "for img_name in tqdm(image_files, desc=\"Extracting HOG features...\"):\n",
        "    if img_name in labels:\n",
        "        img_path = os.path.join(data_dir, img_name)\n",
        "        hog_features = extract_hog(img_path)\n",
        "        if hog_features is not None:\n",
        "            X.append(hog_features)\n",
        "            y.append(labels[img_name])\n",
        "        else:\n",
        "            print(f\"Skipping {img_path} due to processing error\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Extracted HOG features for {len(X)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-kjLw5EYAb8",
        "outputId": "4d8e9a7b-bdc5-479f-c34e-5aa41638c091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting HOG features...: 100%|██████████| 10004/10004 [04:32<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted HOG features for 10002 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train (70%), validation (15%), and test (15%)\n",
        "X_train_smile, X_temp, y_train_smile, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "X_val_smile, X_test_smile, y_val_smile, y_test_smile = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Train shape: {X_train_smile.shape}, Val shape: {X_val_smile.shape}, Test shape: {X_test_smile.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQummuSirJI_",
        "outputId": "4b8c6cac-fd6e-41ff-ead3-432240119f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (7001, 1764), Val shape: (1500, 1764), Test shape: (1501, 1764)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Standardize and reduce dimensionality with PCA\n",
        "scaler = StandardScaler()\n",
        "pca = PCA(n_components=200, random_state=42)\n",
        "\n",
        "# Apply scaling and PCA to smile data\n",
        "X_train_smile = scaler.fit_transform(X_train_smile)\n",
        "X_val_smile = scaler.transform(X_val_smile)\n",
        "X_test_smile = scaler.transform(X_test_smile)\n",
        "X_train_smile = pca.fit_transform(X_train_smile)\n",
        "X_val_smile = pca.transform(X_val_smile)\n",
        "X_test_smile = pca.transform(X_test_smile)\n",
        "\n",
        "print(f\"Preprocessed feature shapes: Train {X_train_smile.shape}, Val {X_val_smile.shape}, Test {X_test_smile.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF7772ZqvAuR",
        "outputId": "d584d430-9ded-4be1-cf47-464eab5b0619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed feature shapes: Train (7001, 200), Val (1500, 200), Test (1501, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the SGDClassifier\n",
        "sgd_clf = SGDClassifier(loss='log_loss', random_state=42, max_iter=20)\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization strength\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
        "    'eta0': [0.001, 0.01, 0.1],  # Initial learning rate (for constant/invscaling)\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation on validation set\n",
        "grid_search = GridSearchCV(\n",
        "    sgd_clf,\n",
        "    param_grid,\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,  # Use all available cores\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit grid search on training data\n",
        "grid_search.fit(X_train_smile, y_train_smile)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use best model for validation set prediction\n",
        "best_model = grid_search.best_estimator_\n",
        "y_val_pred = best_model.predict(X_val_smile)\n",
        "val_accuracy = accuracy_score(y_val_smile, y_val_pred)\n",
        "print(f\"Validation accuracy with best model: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8pQGEiCwGzG",
        "outputId": "06aa23e8-1802-4133-be62-3a19988c4456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Best parameters: {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'invscaling'}\n",
            "Best cross-validation accuracy: 0.8124559476179299\n",
            "Validation accuracy with best model: 0.8173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define SGDClassifier with fixed best parameters\n",
        "sgd_clf = SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    alpha=0.0001,\n",
        "    learning_rate='invscaling',\n",
        "    eta0=0.01,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Define grid for max_iter\n",
        "param_grid = {\n",
        "    'max_iter': [20, 50, 100, 200]\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search_epochs = GridSearchCV(\n",
        "    sgd_clf,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "grid_search_epochs.fit(X_train_smile, y_train_smile)\n",
        "\n",
        "# Print results\n",
        "print(\"Best epoch parameters:\", grid_search_epochs.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search_epochs.best_score_)\n",
        "\n",
        "# Evaluate on validation set\n",
        "best_model_epochs = grid_search_epochs.best_estimator_\n",
        "y_val_pred = best_model_epochs.predict(X_val_smile)\n",
        "val_accuracy = accuracy_score(y_val_smile, y_val_pred)\n",
        "print(f\"Validation accuracy with best epochs: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUT_5JF6wHYe",
        "outputId": "63e19946-b854-4c00-f486-587b5836afe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Best epoch parameters: {'max_iter': 20}\n",
            "Best cross-validation accuracy: 0.8123130700639937\n",
            "Validation accuracy with best epochs: 0.8173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Combine training and validation sets for final training\n",
        "X_train_val_smile = np.vstack((X_train_smile, X_val_smile))\n",
        "y_train_val_smile = np.hstack((y_train_smile, y_val_smile))\n",
        "\n",
        "# Initialize SGDClassifier with best parameters and increased epochs\n",
        "sgd_clf = SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    alpha=0.0001,\n",
        "    learning_rate='invscaling',\n",
        "    eta0=0.01,\n",
        "    max_iter=50,  # Increased from 20 to 50 for better convergence\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "sgd_clf.fit(X_train_val_smile, y_train_val_smile)\n",
        "\n",
        "print(\"Model training completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GspYGpwgxvvo",
        "outputId": "78445a04-8dcf-4c9b-e489-5de1668f982f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predict on test set\n",
        "y_test_pred = sgd_clf.predict(X_test_smile)\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(y_test_smile, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_smile, y_test_pred, target_names=['Non-Smiling', 'Smiling']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NaImx3E07yE",
        "outputId": "0f0a057c-d14a-4dcb-c94e-2ce2431c8d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8168\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Non-Smiling       0.82      0.84      0.83       777\n",
            "     Smiling       0.82      0.80      0.81       724\n",
            "\n",
            "    accuracy                           0.82      1501\n",
            "   macro avg       0.82      0.82      0.82      1501\n",
            "weighted avg       0.82      0.82      0.82      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(sgd_clf, '/content/drive/MyDrive/Smilage_Project_Data/sgd_clf_model.pkl')\n",
        "print(\"Model saved to /content/drive/MyDrive/Smilage_Project_Data/sgd_clf_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU7Q9vIC1Ook",
        "outputId": "8e937d77-b6dd-41b5-e08f-111b87e08f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/Smilage_Project_Data/sgd_clf_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io, color, transform\n",
        "from skimage.feature import hog\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(image_path, scaler, pca):\n",
        "    try:\n",
        "        img = io.imread(image_path)\n",
        "        if len(img.shape) == 3:\n",
        "            img = color.rgb2gray(img)\n",
        "        img = transform.resize(img, (64, 64), anti_aliasing=True)\n",
        "        hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
        "        hog_features = scaler.transform([hog_features])  # Standardize\n",
        "        hog_features = pca.transform(hog_features)  # Apply PCA\n",
        "        return hog_features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Predict on a new image\n",
        "image_path = '/content/drive/MyDrive/Smilage_Project_Data/test_image.jpg'  # Replace with your uploaded image path\n",
        "hog_features = preprocess_image(image_path, scaler, pca)\n",
        "if hog_features is not None:\n",
        "    prediction = sgd_clf.predict(hog_features)\n",
        "    confidence = sgd_clf.predict_proba(hog_features)[0][prediction[0]]\n",
        "    label = 'Smiling' if prediction[0] == 1 else 'Non-Smiling'\n",
        "    print(f\"Prediction: {label} (Confidence: {confidence:.4f})\")\n",
        "else:\n",
        "    print(\"Failed to process the image\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r-7nsAv1uVJ",
        "outputId": "da06b028-003f-47b3-91bc-83aa6a8105bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Smiling (Confidence: 0.7844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io, color, transform\n",
        "from skimage.feature import hog\n",
        "import numpy as np\n",
        "\n",
        "# Function to preprocess a single image (matches CelebA training pipeline)\n",
        "def preprocess_image(image_path, scaler, pca):\n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        img = io.imread(image_path)\n",
        "        if len(img.shape) == 3:\n",
        "            img = color.rgb2gray(img)  # Convert to grayscale\n",
        "        img = transform.resize(img, (64, 64), anti_aliasing=True)  # Resize to 64x64\n",
        "        # Extract HOG features (same parameters as Cell 3)\n",
        "        hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
        "        # Standardize and apply PCA (using scaler and pca from Cell 4)\n",
        "        hog_features = scaler.transform([hog_features])\n",
        "        hog_features = pca.transform(hog_features)\n",
        "        return hog_features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Specify path to your uploaded .jpg image\n",
        "image_path = '/content/drive/MyDrive/Smilage_Project_Data/test1_image.jpg'  # Replace with your image path\n",
        "\n",
        "# Preprocess and predict\n",
        "hog_features = preprocess_image(image_path, scaler, pca)\n",
        "if hog_features is not None:\n",
        "    prediction = sgd_clf.predict(hog_features)\n",
        "    confidence = sgd_clf.predict_proba(hog_features)[0][prediction[0]]\n",
        "    label = 'Smiling' if prediction[0] == 1 else 'Non-Smiling'\n",
        "    print(f\"Prediction: {label} (Confidence: {confidence:.4f})\")\n",
        "else:\n",
        "    print(\"Failed to process the image. Check file path or image format.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2l5fVml56SK",
        "outputId": "e695d5ad-2724-462c-e116-2e9e32b11cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Non-Smiling (Confidence: 0.7278)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}